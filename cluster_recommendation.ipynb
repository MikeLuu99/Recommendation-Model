{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(\"ml-latest-small/movies.csv\")\n",
    "ratings_df = pd.read_csv(\"ml-latest-small/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of movies (9742, 3)\n",
      "Dimension of ratings (100836, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dimension of movies {movies_df.shape}\\nDimension of ratings {ratings_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = len(ratings_df.userId.unique())\n",
    "n_items = len(ratings_df.movieId.unique())\n",
    "movie_names = movies_df.set_index('movieId')['title'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "\n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        # create user embeddings\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors) # think of this as a lookup table for the input.\n",
    "        # create item embeddings\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors) # think of this as a lookup table for the input.\n",
    "        self.user_factors.weight.data.uniform_(0, 0.05)\n",
    "        self.item_factors.weight.data.uniform_(0, 0.05)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # matrix multiplication\n",
    "        users, items = data[:,0], data[:,1]\n",
    "        return (self.user_factors(users)*self.item_factors(items)).sum(1)\n",
    "\n",
    "    def predict(self, user, item):\n",
    "        return self.forward(user, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataloader (necessary for PyTorch)\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader # package that helps transform your data to machine learning readiness\n",
    "\n",
    "class Loader(Dataset):\n",
    "    def __init__(self):\n",
    "        self.ratings = ratings_df.copy()\n",
    "        \n",
    "        # Extract all user IDs and movie IDs\n",
    "        users = ratings_df.userId.unique()\n",
    "        movies = ratings_df.movieId.unique()\n",
    "        \n",
    "        #--- Producing new continuous IDs for users and movies ---\n",
    "        \n",
    "        # Unique values : index\n",
    "        self.userid2idx = {o:i for i,o in enumerate(users)}\n",
    "        self.movieid2idx = {o:i for i,o in enumerate(movies)}\n",
    "        \n",
    "        # Obtained continuous ID for users and movies\n",
    "        self.idx2userid = {i:o for o,i in self.userid2idx.items()}\n",
    "        self.idx2movieid = {i:o for o,i in self.movieid2idx.items()}\n",
    "        \n",
    "        # return the id from the indexed values as noted in the lambda function down below.\n",
    "        self.ratings.movieId = ratings_df.movieId.apply(lambda x: self.movieid2idx[x])\n",
    "        self.ratings.userId = ratings_df.userId.apply(lambda x: self.userid2idx[x])\n",
    "        \n",
    "        \n",
    "        self.x = self.ratings.drop(['rating', 'timestamp'], axis=1).values\n",
    "        self.y = self.ratings['rating'].values\n",
    "        self.x, self.y = torch.tensor(self.x), torch.tensor(self.y) # Transforms the data to tensors (ready for torch models.)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is running on GPU: False\n",
      "MatrixFactorization(\n",
      "  (user_factors): Embedding(610, 8)\n",
      "  (item_factors): Embedding(9724, 8)\n",
      ")\n",
      "user_factors.weight tensor([[0.0305, 0.0073, 0.0380,  ..., 0.0219, 0.0074, 0.0336],\n",
      "        [0.0189, 0.0146, 0.0146,  ..., 0.0325, 0.0434, 0.0187],\n",
      "        [0.0377, 0.0300, 0.0040,  ..., 0.0203, 0.0106, 0.0438],\n",
      "        ...,\n",
      "        [0.0027, 0.0424, 0.0046,  ..., 0.0106, 0.0159, 0.0052],\n",
      "        [0.0056, 0.0256, 0.0232,  ..., 0.0469, 0.0130, 0.0187],\n",
      "        [0.0497, 0.0004, 0.0367,  ..., 0.0112, 0.0198, 0.0099]])\n",
      "item_factors.weight tensor([[0.0123, 0.0169, 0.0232,  ..., 0.0400, 0.0498, 0.0355],\n",
      "        [0.0013, 0.0213, 0.0139,  ..., 0.0043, 0.0237, 0.0086],\n",
      "        [0.0347, 0.0142, 0.0052,  ..., 0.0289, 0.0135, 0.0360],\n",
      "        ...,\n",
      "        [0.0072, 0.0195, 0.0045,  ..., 0.0073, 0.0101, 0.0042],\n",
      "        [0.0271, 0.0118, 0.0036,  ..., 0.0281, 0.0093, 0.0065],\n",
      "        [0.0487, 0.0265, 0.0012,  ..., 0.0210, 0.0408, 0.0369]])\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "print(\"Is running on GPU:\", cuda)\n",
    "\n",
    "model = MatrixFactorization(n_users, n_items, n_factors=8)\n",
    "print(model)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "# GPU enable if you have a GPU...\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "# MSE loss\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# ADAM optimizier\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Train data\n",
    "train_set = Loader()\n",
    "train_loader = DataLoader(train_set, 128, shuffle=True)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x12d05216210>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd813b68f5264138924c36ab7dd86d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for it in tqdm(range(num_epochs)):\n",
    "    losses = []\n",
    "    for x, y in train_loader:\n",
    "        if cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = loss_fn(outputs.squeeze(), y.type(torch.float32))\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9724"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_movie_embeddings = model.item_factors.weight.data.cpu().numpy()\n",
    "len(trained_movie_embeddings) # unique movie factor weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# Fit the clusters based on the movie weights\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(trained_movie_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster #0\n",
      "\t Pulp Fiction (1994)\n",
      "\t Jurassic Park (1993)\n",
      "\t American Beauty (1999)\n",
      "\t Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\n",
      "\t Pretty Woman (1990)\n",
      "\t Terminator, The (1984)\n",
      "\t Fifth Element, The (1997)\n",
      "\t Net, The (1995)\n",
      "\t Star Trek: Generations (1994)\n",
      "\t Up (2009)\n",
      "Cluster #1\n",
      "\t Star Wars: Episode V - The Empire Strikes Back (1980)\n",
      "\t Star Wars: Episode VI - Return of the Jedi (1983)\n",
      "\t Godfather, The (1972)\n",
      "\t Good Will Hunting (1997)\n",
      "\t Austin Powers: The Spy Who Shagged Me (1999)\n",
      "\t Green Mile, The (1999)\n",
      "\t Jumanji (1995)\n",
      "\t Shining, The (1980)\n",
      "\t Interview with the Vampire: The Vampire Chronicles (1994)\n",
      "\t Departed, The (2006)\n",
      "Cluster #2\n",
      "\t Fugitive, The (1993)\n",
      "\t Lord of the Rings: The Return of the King, The (2003)\n",
      "\t Sixth Sense, The (1999)\n",
      "\t Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
      "\t Gladiator (2000)\n",
      "\t Men in Black (a.k.a. MIB) (1997)\n",
      "\t Die Hard (1988)\n",
      "\t Princess Bride, The (1987)\n",
      "\t Monty Python and the Holy Grail (1975)\n",
      "\t Dumb & Dumber (Dumb and Dumber) (1994)\n",
      "Cluster #3\n",
      "\t Toy Story (1995)\n",
      "\t Apollo 13 (1995)\n",
      "\t Lord of the Rings: The Fellowship of the Ring, The (2001)\n",
      "\t Back to the Future (1985)\n",
      "\t Batman Forever (1995)\n",
      "\t Goodfellas (1990)\n",
      "\t Twister (1996)\n",
      "\t Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\n",
      "\t Ocean's Eleven (2001)\n",
      "\t Clear and Present Danger (1994)\n",
      "Cluster #4\n",
      "\t Shawshank Redemption, The (1994)\n",
      "\t Dark Knight, The (2008)\n",
      "\t Groundhog Day (1993)\n",
      "\t Inception (2010)\n",
      "\t Finding Nemo (2003)\n",
      "\t American History X (1998)\n",
      "\t Truman Show, The (1998)\n",
      "\t Blade Runner (1982)\n",
      "\t Willy Wonka & the Chocolate Factory (1971)\n",
      "\t Bourne Identity, The (2002)\n",
      "Cluster #5\n",
      "\t Braveheart (1995)\n",
      "\t Terminator 2: Judgment Day (1991)\n",
      "\t Lord of the Rings: The Two Towers, The (2002)\n",
      "\t Memento (2000)\n",
      "\t Mrs. Doubtfire (1993)\n",
      "\t Die Hard: With a Vengeance (1995)\n",
      "\t Stargate (1994)\n",
      "\t Indiana Jones and the Last Crusade (1989)\n",
      "\t Star Wars: Episode I - The Phantom Menace (1999)\n",
      "\t Aliens (1986)\n",
      "Cluster #6\n",
      "\t Usual Suspects, The (1995)\n",
      "\t Seven (a.k.a. Se7en) (1995)\n",
      "\t Batman (1989)\n",
      "\t Fargo (1996)\n",
      "\t True Lies (1994)\n",
      "\t Kill Bill: Vol. 1 (2003)\n",
      "\t Godfather: Part II, The (1974)\n",
      "\t Ghost (1990)\n",
      "\t Catch Me If You Can (2002)\n",
      "\t Kill Bill: Vol. 2 (2004)\n",
      "Cluster #7\n",
      "\t Star Wars: Episode IV - A New Hope (1977)\n",
      "\t Fight Club (1999)\n",
      "\t Aladdin (1992)\n",
      "\t Dances with Wolves (1990)\n",
      "\t Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
      "\t Titanic (1997)\n",
      "\t Monsters, Inc. (2001)\n",
      "\t Incredibles, The (2004)\n",
      "\t Clockwork Orange, A (1971)\n",
      "\t Minority Report (2002)\n",
      "Cluster #8\n",
      "\t Silence of the Lambs, The (1991)\n",
      "\t Schindler's List (1993)\n",
      "\t Speed (1994)\n",
      "\t Shrek (2001)\n",
      "\t Mission: Impossible (1996)\n",
      "\t Ace Ventura: Pet Detective (1994)\n",
      "\t Mask, The (1994)\n",
      "\t Alien (1979)\n",
      "\t Eternal Sunshine of the Spotless Mind (2004)\n",
      "\t E.T. the Extra-Terrestrial (1982)\n",
      "Cluster #9\n",
      "\t Forrest Gump (1994)\n",
      "\t Matrix, The (1999)\n",
      "\t Independence Day (a.k.a. ID4) (1996)\n",
      "\t Saving Private Ryan (1998)\n",
      "\t Lion King, The (1994)\n",
      "\t Beauty and the Beast (1991)\n",
      "\t X-Men (2000)\n",
      "\t One Flew Over the Cuckoo's Nest (1975)\n",
      "\t GoldenEye (1995)\n",
      "\t Reservoir Dogs (1992)\n"
     ]
    }
   ],
   "source": [
    "for cluster in range(10):\n",
    "  print(\"Cluster #{}\".format(cluster))\n",
    "  movs = []\n",
    "  for movidx in np.where(kmeans.labels_ == cluster)[0]:\n",
    "    movid = train_set.idx2movieid[movidx]\n",
    "    rat_count = ratings_df.loc[ratings_df['movieId']==movid].count()[0]\n",
    "    movs.append((movie_names[movid], rat_count))\n",
    "  for mov in sorted(movs, key=lambda tup: tup[1], reverse=True)[:10]:\n",
    "    print(\"\\t\", mov[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn",
   "language": "python",
   "name": "cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
